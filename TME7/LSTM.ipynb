{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEAM SEARCH\n",
    "- Pour une couche, tire n character et stocker les plus propables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM\n",
    "- genere les parantheses (automates) pour montrer que rnn va les oublie mais LSTM non"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n",
    "\n",
    "from torch import nn\n",
    "import torch\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tools import AverageMeter\n",
    "\n",
    "from charDataset import CharDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        c_size = input_size + hidden_size\n",
    "        self.C = torch.zeros(hidden_size,1)\n",
    "        self.f_t = nn.Linear(in_features=c_size, out_features=hidden_size, bias=True)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.f_t2 = nn.Linear(in_features=c_size, out_features=hidden_size, bias=True)\n",
    "        self.C_t = nn.Linear(in_features=c_size, out_features=hidden_size, bias=True)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.out = nn.Linear(in_features=c_size, out_features=hidden_size, bias=True)\n",
    "        \n",
    "    def forward(self, h, x):\n",
    "        combined = torch.cat((h,x), dim=0).t()\n",
    "        \n",
    "        # CLEAR\n",
    "        f_t = self.sigmoid(self.f_t(combined)).t()\n",
    "        self.C = self.C * f_t\n",
    "        print(self.C.shape)\n",
    "        \n",
    "        # WRITE\n",
    "        i_t = (self.sigmoid(self.f_t2(combined)) * self.tanh(self.C_t(combined))).t()\n",
    "        self.C = self.C + i_t\n",
    "        print(self.C.shape)\n",
    "        \n",
    "        # READ\n",
    "        out = self.sigmoid(self.out(combined)).t()\n",
    "        h_ = self.C * out\n",
    "        print(self.C.shape)\n",
    "        return h_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([455, 1])\n",
      "torch.Size([455, 1])\n",
      "torch.Size([455, 1])\n",
      "torch.Size([455, 1])\n",
      "torch.Size([455, 1])\n",
      "torch.Size([455, 1])\n",
      "torch.Size([455, 1])\n",
      "torch.Size([455, 1])\n",
      "torch.Size([455, 1])\n",
      "torch.Size([455, 1])\n",
      "torch.Size([455, 1])\n",
      "torch.Size([455, 1])\n",
      "torch.Size([455, 1])\n",
      "torch.Size([455, 1])\n",
      "torch.Size([455, 1])\n"
     ]
    }
   ],
   "source": [
    "input_size = 9\n",
    "hidden_size = 455\n",
    "lstm = LSTM(input_size,hidden_size)\n",
    "x = torch.zeros(input_size,1)\n",
    "h = torch.zeros(hidden_size,1)\n",
    "for i in range(5):\n",
    "    h = lstm(h,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cutting off end of data so that the batches/sequences divide evenly\n"
     ]
    }
   ],
   "source": [
    "cdataset = CharDataset('train_data.tx', 'vocab.tx', 10)\n",
    "dataload = DataLoader(cdataset,batch_size=100,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "for (batch, target) in dataload:\n",
    "    print(target.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
